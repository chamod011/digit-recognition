{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c845c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models found in repo root: ['mnist_cnn.h5']\n"
     ]
    }
   ],
   "source": [
    "# List available saved models in the current folder\n",
    "import os\n",
    "models = [f for f in os.listdir('.') if f.lower().endswith(('.h5', '.joblib', '.pkl'))]\n",
    "print('Models found in repo root:', models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e3f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and helper functions\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_model_auto(path):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in ('.h5', '.keras'):\n",
    "        try:\n",
    "            from tensorflow.keras.models import load_model\n",
    "            return 'keras', load_model(path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Failed to load Keras model: '+str(e))\n",
    "    if ext in ('.joblib', '.pkl'):\n",
    "        try:\n",
    "            import joblib\n",
    "            return 'sklearn', joblib.load(path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Failed to load sklearn model: '+str(e))\n",
    "    # try keras first, then sklearn\n",
    "    try:\n",
    "        from tensorflow.keras.models import load_model\n",
    "        return 'keras', load_model(path)\n",
    "    except Exception:\n",
    "        import joblib\n",
    "        return 'sklearn', joblib.load(path)\n",
    "\n",
    "def preprocess_for_keras(image_path, invert=False):\n",
    "    # Keras MNIST model expects (1,28,28,1), values 0-1\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((28,28), Image.Resampling.LANCZOS)\n",
    "    arr = np.array(img).astype('float32')\n",
    "    if invert:\n",
    "        arr = 255.0 - arr\n",
    "    arr = arr / 255.0\n",
    "    arr = arr.reshape((1,28,28,1))\n",
    "    return arr, img\n",
    "\n",
    "def preprocess_for_sklearn(image_path, invert=False):\n",
    "    # sklearn digits (8x8) expects shape (n_samples, 64), scaled ~0-16 in original dataset\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((8,8), Image.Resampling.LANCZOS)\n",
    "    arr = np.array(img).astype('float32')\n",
    "    if invert:\n",
    "        arr = 255.0 - arr\n",
    "    # scale to 0-16 like sklearn digits: divide by 255 and multiply by 16 then flatten\n",
    "    arr = (arr / 255.0) * 16.0\n",
    "    arr = arr.reshape((1, -1))\n",
    "    return arr, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c20c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "Predicted label: 0\n",
      "Probabilities: [0.4758724  0.07508563 0.06464657 0.02350072 0.10353672 0.0158121\n",
      " 0.12036983 0.04709152 0.0630158  0.01106875]\n",
      "Predicted label: 0\n",
      "Probabilities: [0.4758724  0.07508563 0.06464657 0.02350072 0.10353672 0.0158121\n",
      " 0.12036983 0.04709152 0.0630158  0.01106875]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure these paths before running:\n",
    "MODEL_PATH = 'mnist_cnn.h5'   # change to your model file if different\n",
    "IMAGE_PATH = 'test_digit.png' # path to the image you want to test\n",
    "INVERT = False                # set True if foreground/background are inverted\n",
    "\n",
    "# Load model and run prediction\n",
    "assert os.path.exists(MODEL_PATH), f'Model file not found: {MODEL_PATH}'\n",
    "assert os.path.exists(IMAGE_PATH), f'Image file not found: {IMAGE_PATH}'\n",
    "mtype, model = load_model_auto(MODEL_PATH)\n",
    "print('Detected model type:', mtype)\n",
    "if mtype == 'keras':\n",
    "    x, img = preprocess_for_keras(IMAGE_PATH, invert=INVERT)\n",
    "    preds = model.predict(x)\n",
    "    label = int(np.argmax(preds, axis=1)[0])\n",
    "    print('Predicted label:', label)\n",
    "    print('Probabilities:', preds[0])\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f'Pred: {label}')\n",
    "    plt.axis('off')\n",
    "else:\n",
    "    # sklearn classifier\n",
    "    x, img = preprocess_for_sklearn(IMAGE_PATH, invert=INVERT)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probs = model.predict_proba(x)[0]\n",
    "        label = int(np.argmax(probs))\n",
    "        print('Predicted label:', label)\n",
    "        print('Probabilities:', probs)\n",
    "    else:\n",
    "        label = int(model.predict(x)[0])\n",
    "        print('Predicted label:', label)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    # for sklearn digits, show the resized 8x8 image scaled up for clarity\n",
    "    plt.imshow(img.resize((56,56), Image.Resampling.NEAREST), cmap='gray')\n",
    "    plt.title(f'Pred: {label}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b1ae7",
   "metadata": {},
   "source": [
    "**Tips & Troubleshooting**\n",
    "- If your predictions are wrong, try: cropping tightly around the digit, converting to grayscale, and setting `INVERT=True` if the background is white and digit is dark (or vice versa).\n",
    "- For Keras MNIST models, images should be 28x28 pixels and normalized. For the sklearn `digits` model, images should be 8x8.\n",
    "- If a model file isn't found, place it in the repository root or set `MODEL_PATH` to its correct path.\n",
    "- To test multiple images, loop over a list of `IMAGE_PATH`s and run the preprocess + predict block for each."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
